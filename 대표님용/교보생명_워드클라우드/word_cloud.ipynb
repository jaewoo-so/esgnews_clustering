{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f447e14e-8a95-44fb-bc99-e9e83cdee756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import feedparser\n",
    "from newspaper import Article\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33c7a85b-178f-4663-ab91-7fcd310139cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contents(link):\n",
    "        article = Article(link, language='ko')\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        return article.text\n",
    "\n",
    "def cleaning_korean(content):\n",
    "    content = content.replace('\\n\\n','')\n",
    "    content = ' '.join(content.split(' '))\n",
    "\n",
    "    #클리닝1\n",
    "    content = re.sub(r'... 기자', '', content)\n",
    "    content = re.sub(r'...기자', '', content)\n",
    "\n",
    "    #괄호안 제거 \n",
    "    ''' 괄호안 내용 제거하기 '''\n",
    "    pattern_bracket1 = r'\\([^)]*\\)'\n",
    "    pattern_bracket2 = r'\\{[^)]*\\}'\n",
    "    pattern_bracket3 = r'\\<[^)]*\\>'\n",
    "    pattern_bracket4 = r'\\[[^)]*\\]'\n",
    "\n",
    "    x = '이건 {괄호 안의 불필요한 정보를} 삭제하는 코드다.'\n",
    "    content = re.sub(pattern=pattern_bracket1, repl='', string= content)\n",
    "    content = ' '.join(content.split())\n",
    "    content = re.sub(pattern=pattern_bracket2, repl='', string= content)\n",
    "    content = ' '.join(content.split())\n",
    "    content = re.sub(pattern=pattern_bracket3, repl='', string= content)\n",
    "    content = ' '.join(content.split())\n",
    "    content = re.sub(pattern=pattern_bracket4, repl='', string= content)\n",
    "    content = ' '.join(content.split())\n",
    "    #클리닝\n",
    "    content = content.lower() #lower case\n",
    "    pattern = '([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)' # E-mail제거\n",
    "    content = re.sub(pattern=pattern, repl='', string=content)\n",
    "    pattern = '(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+' # URL제거\n",
    "    content = re.sub(pattern=pattern, repl='', string=content)\n",
    "    # 특수기호 특수\n",
    "    content = re.sub('[-=+#/\\?:^$@*\\\"※~%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》Δ△·“=◎<>▷]', '', content)\n",
    "    content = re.sub('[一-龥]', '',content)\n",
    "    #pattern = '[^\\w\\s]'         # 특수기호제거\n",
    "    #content = re.sub(r'[@%\\\\*=()/~#&\\+á?\\xc3\\xa1\\-\\|\\:\\;\\!\\-\\,\\_\\~\\$\\'\\\"]', '',str(content)) #remove punctuation\n",
    "    content = re.sub(r\"[^a-zA-Z0-9가-힣\\.\\s]\",\"\",content)\n",
    "    content = re.sub(pattern=pattern, repl='', string=content)\n",
    "    content = re.sub(r'\\s+', ' ', content) #remove extra space\n",
    "    content = re.sub(r'<[^>]+>','',content) #remove Html tags\n",
    "    content = re.sub(r'\\s+', ' ', content) #remove spaces\n",
    "    content = re.sub(r\"^\\s+\", '', content) #remove space from start\n",
    "    content = re.sub(r'\\s+$', '', content) #remove space from the end\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52146101-2dbf-44aa-8bde-27d585c3b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflink = pd.read_csv('./news_url.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f988b9f-cbf9-4b80-b742-36901bd8a573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.thebell.co.kr/free/content/ArticleView.asp?key=202201211614241520101893&lcode=00\n",
      "https://www.ajunews.com/view/20211201050234882 \n",
      "https://www.fnnews.com/news/202111281735005130 \n",
      "Article `download()` failed with 404 Client Error: Not Found for url: https://www.hankyung.com/economy/article/202212145008i%20 on URL https://www.hankyung.com/economy/article/202212145008i \n",
      "https://www.ajunews.com/view/20221130171222768\n",
      "https://www.edaily.co.kr/news/read?newsId=02079526592972528&mediaCodeNo=257\n",
      "https://www.etoday.co.kr/news/view/387113\n",
      "https://www.newspim.com/news/view/20110411000013\n",
      "https://www.thebell.co.kr/free/content/ArticleView.asp?key=201801040100006950000414&lcode=00 \n",
      "Article `download()` failed with 404 Client Error: Not Found for url: https://www.hankyung.com/economy/article/2018010327901%20 on URL https://www.hankyung.com/economy/article/2018010327901 \n",
      "http://m.ddaily.co.kr/m/m_article/?no=164321 \n",
      "https://www.edaily.co.kr/news/read?newsId=03440726619074112&mediaCodeNo=2 \n",
      "Article `download()` failed with 404 Client Error: Not Found for url: https://www.newsway.co.kr/news/view?ud=2018080115271559035%20 on URL https://www.newsway.co.kr/news/view?ud=2018080115271559035 \n",
      "'float' object has no attribute 'decode'\n",
      "'float' object has no attribute 'decode'\n",
      "'float' object has no attribute 'decode'\n",
      "'float' object has no attribute 'decode'\n",
      "'float' object has no attribute 'decode'\n",
      "'float' object has no attribute 'decode'\n",
      "----------\n",
      "Article `download()` failed with 404 Client Error: Not Found for url: https://biz.chosun.com/distribution/channel/2023/02/10/EJONGEG2TZHX5PMNLKMRIUE5RE/%20/ on URL https://biz.chosun.com/distribution/channel/2023/02/10/EJONGEG2TZHX5PMNLKMRIUE5RE/ \n",
      "You must `download()` an article first!\n",
      "You must `download()` an article first!\n",
      "Article `download()` failed with 404 Client Error: Not Found for url: http://www.investchosun.com/site/data/html_dir/2023/02/14/2023021480259.html%20 on URL http://www.investchosun.com/site/data/html_dir/2023/02/14/2023021480259.html \n",
      "Article `download()` failed with 404 Client Error: Not Found for url: https://alphabiz.co.kr/news/view/1065592283504212%20 on URL https://alphabiz.co.kr/news/view/1065592283504212 \n",
      "You must `download()` an article first!\n",
      "https://dealsite.co.kr/articles/75211 \n",
      "Article `download()` failed with 404 Client Error: Not Found for url: https://biz.chosun.com/distribution/channel/2023/02/10/EJONGEG2TZHX5PMNLKMRIUE5RE/%20/ on URL https://biz.chosun.com/distribution/channel/2023/02/10/EJONGEG2TZHX5PMNLKMRIUE5RE/ \n",
      "https://biz.sbs.co.kr/article/20000102992 \n",
      "https://news.mt.co.kr/mtview.php?no=2021110821124918189 \n",
      "You must `download()` an article first!\n",
      "http://www.investchosun.com/m/article.html?contid=2021122980124 \n",
      "You must `download()` an article first!\n",
      "https://www.hani.co.kr/arti/economy/car/845581.html \n",
      "https://www.fnnews.com/news/202104141819412187 \n",
      "https://www.etnews.com/20180328000331\n",
      "https://biz.newdaily.co.kr/site/data/html/2018/03/28/2018032810109.html\n",
      "http://www.bizhankook.com/bk/article/15525\n",
      "https://news.einfomax.co.kr/news/articleView.html?idxno=3441115\n"
     ]
    }
   ],
   "source": [
    "p_contents = []\n",
    "for url in dflink['p']:\n",
    "    try:\n",
    "        p_contents.append(  cleaning_korean(get_contents(url) ))\n",
    "        print(url)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "print('----------')\n",
    "n_contents = []\n",
    "for url in dflink['n']:\n",
    "    try:\n",
    "        n_contents.append(  cleaning_korean(get_contents(url) ))\n",
    "        print(url)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ebb306b-9368-4f5a-8413-33761daff2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "\n",
    "def content2noun_mecab(series_content, save_path = None):\n",
    "    try:\n",
    "        tokenizer = Mecab() \n",
    "    except:\n",
    "        tokenizer = Mecab('C:\\mecab\\mecab-ko-dic') \n",
    "    res_list = []\n",
    "    print('------ start mecab tokenizer ------')\n",
    "    for row in series_content:\n",
    "        try:\n",
    "            res = ' '.join(tokenizer.nouns(row))\n",
    "            res_list.append(res)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            res_list.append('')\n",
    "    return res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8323223b-0d81-464b-9e96-cbdabedf94a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ start mecab tokenizer ------\n",
      "------ start mecab tokenizer ------\n",
      "------ start mecab tokenizer ------\n",
      "------ start mecab tokenizer ------\n",
      "------ start mecab tokenizer ------\n",
      "------ start mecab tokenizer ------\n",
      "------ start mecab tokenizer ------\n",
      "------ start mecab tokenizer ------\n",
      "------ start mecab tokenizer ------\n",
      "------ start mecab tokenizer ------\n",
      "------ start mecab tokenizer ------\n",
      "------ start mecab tokenizer ------\n",
      "------ start mecab tokenizer ------\n",
      "------ start mecab tokenizer ------\n",
      "------ start mecab tokenizer ------\n",
      "------ start mecab tokenizer ------\n",
      "------ start mecab tokenizer ------\n",
      "------ start mecab tokenizer ------\n",
      "------ start mecab tokenizer ------\n",
      "------ start mecab tokenizer ------\n"
     ]
    }
   ],
   "source": [
    "pc = []\n",
    "for c in p_contents:\n",
    "    pc.append(content2noun_mecab(c))\n",
    "\n",
    "nc =[]\n",
    "for c in n_contents:\n",
    "    nc.append(content2noun_mecab(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ce13495-33e6-4715-b140-86d8cae8e052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ start mecab tokenizer ------\n",
      "------ start mecab tokenizer ------\n"
     ]
    }
   ],
   "source": [
    "pres = content2noun_mecab(p_contents)\n",
    "nres = content2noun_mecab(n_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf6074a5-9e70-4a1f-9fb3-03b1ca96c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = []\n",
    "for res in pres:\n",
    "    pl = pl+res.split(' ')\n",
    "    \n",
    "nl = []\n",
    "for res in nres:\n",
    "    nl = nl+res.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6833d6a-2097-47f0-8cea-a41d4ddfc8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pclean = []\n",
    "for cc in pl:\n",
    "    if len(cc) < 2:\n",
    "        continue\n",
    "    else:\n",
    "        pclean.append(cc)\n",
    "        \n",
    "nclean = []\n",
    "for cc in nl:\n",
    "    if len(cc) < 2:\n",
    "        continue\n",
    "    else:\n",
    "        nclean.append(cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7816c8d-0495-4262-bca6-9e2005afc074",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecfd38cf-e0f6-4f6b-9cdc-50989896c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7445bda-848b-41a0-bb35-c4861106c43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(pclean):\n",
    "    dfp = pd.DataFrame()\n",
    "    dfp['count'] = pclean\n",
    "    \n",
    "    dfpc = dfp.value_counts().to_frame()\n",
    "    dfpc['word'] =  dfpc.index\n",
    "    dfpc = dfpc.reset_index(drop=True)\n",
    "    dfpc['word'] = dfpc['word'].apply(lambda x : x[0])\n",
    "    dfpc.columns = ['count','word']\n",
    "    \n",
    "    #dfpc = dfpc.loc[dfpc['count'] > 1]\n",
    "\n",
    "    return dfpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7000ae6-640f-451f-9c22-001c6353556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpc = get_count(pclean)\n",
    "dfnc = get_count(nclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cfa81f8-bcc1-4b91-98d2-bd7cbece171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpc.to_csv('ppp_raw_include1.csv')\n",
    "dfnc.to_csv('nnn_raw_include1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190bda6c-7db0-4652-ba2f-1789d0c1241c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a9a2595-4916-4ee9-8d5e-962fb09c3d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c26e5e7-2f12-4069-a31d-a1813a8abb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dif 12312313414124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x209cf85e4f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfpc = pd.read_csv('./10개미만제거/ppp.csv')\n",
    "mx = dfpc['count'].max()\n",
    "mn = dfpc['count'].min()\n",
    "#dfpc['count'] = dfpc['count'].apply(lambda x : int(  (mx - x)/(mx - mn) * 100 ))\n",
    "\n",
    "\n",
    "if len(dfpc) !=  len(set(dfpc['word'].values)):\n",
    "    print('dif 12312313414124')\n",
    "pdict = dict(zip(dfpc['word'] , dfpc['count']))\n",
    "wc = WordCloud(font_path='malgun', width=800, height=800, scale=1.0, max_font_size=800 ,  background_color = 'white')\n",
    "gen = wc.generate_from_frequencies(pdict)\n",
    "wc.to_file('pp_new.png')\n",
    "#plt.figure()\n",
    "#plt.imshow(gen)\n",
    "#Counter(list(dfpc['word'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6f05cdf-d134-4949-b69c-ebb550e63337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dif 12312313414124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x209cfa2c280>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfpc = pd.read_csv('./10개미만제거/nnn.csv', index_col = 0)\n",
    "mx = dfpc['count'].max()\n",
    "mn = dfpc['count'].min()\n",
    "#dfpc['count'] = dfpc['count'].apply(lambda x : int( np.log2( (mx - x)/(mx - mn) + 0.0001 ) + 10 ))\n",
    "\n",
    "if len(dfpc) !=  len(set(dfpc['word'].values)):\n",
    "    print('dif 12312313414124')\n",
    "pdict = dict(zip(dfpc['word'] , dfpc['count']))\n",
    "wc = WordCloud(font_path='malgun', width=800, height=800, scale=1.0, max_font_size=800, background_color = 'white')\n",
    "gen = wc.generate_from_frequencies(pdict)\n",
    "wc.to_file('nn_new.png')\n",
    "#plt.figure()\n",
    "#plt.imshow(gen)\n",
    "#Counter(list(dfpc['word'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "450e8931-97a8-439f-9503-c14c4fae59b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 3.6781201935056934e-08\n",
      "     jac: array([ 0.57693767, -0.11748221])\n",
      " message: 'Optimization terminated successfully'\n",
      "    nfev: 12\n",
      "     nit: 1\n",
      "    njev: 1\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-1.87927581e-04,  3.82678224e-05])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "xs = np.random.randn(1000 , 20)\n",
    "ys = np.random.randn(1000 , 1) * 20\n",
    "\n",
    "# Define the objective function to be minimized\n",
    "def objective(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "# Define the stochastic gradient of the objective function\n",
    "def stochastic_gradient(x):\n",
    "    return np.array( [np.random.normal(2*x[0]), np.random.normal(2*x[1])])\n",
    "\n",
    "# Define the bounds of the search space\n",
    "bounds = [(-1, 1), (-1, 1)] * 10\n",
    "\n",
    "# Call the minimize function with the stochastic gradient method\n",
    "result = minimize(objective, x0=[0, 0], method='SLSQP', jac=stochastic_gradient, bounds=bounds)\n",
    "\n",
    "# Print the optimization result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7436a6a9-0a86-4c68-a852-c936d311982b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.15358615, 40.07703828])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [10,20]\n",
    "np.array( [np.random.normal(2*x[0]), np.random.normal(2*x[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f2414a-0566-432b-a42c-4e6de4500496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp38]",
   "language": "python",
   "name": "conda-env-nlp38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
