{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ddd4fb6-13a3-48da-8188-4fc1b3cffd57",
   "metadata": {},
   "source": [
    "Autor: so jae woo    \n",
    "Data src :  qesg news / 28 cat / 본문 포함.    \n",
    "Summary : KLUE기반의 버트 사정 임베딩 모델 사용.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "588d4543-b74a-430c-b1d6-b30d62ebb730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaewoo/anaconda3/envs/esgmedia/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2023-01-06 15:48:05.760738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 15:48:05.765639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 15:48:05.765801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 15:48:05.766184: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 15:48:05.768148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 15:48:05.768285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 15:48:05.768403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 15:48:06.112131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 15:48:06.112303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 15:48:06.112426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 15:48:06.112533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22308 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:49:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import transformers\n",
    "transformers.__version__ # \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from transformers import TFBertForSequenceClassification\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from transformers import TextClassificationPipeline\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from lib_offline import prep_mecab_noun_offline\n",
    "from lib2 import text_preprocessing\n",
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6500f9a2-4bc6-4e44-bbd5-2f80eb8371c9",
   "metadata": {},
   "source": [
    "# 데이터 준비 \n",
    "## QESG 데이터 준비 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04865168-2422-4016-9935-a7617f43612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qesg = pd.read_parquet(\"./df_qesg28_final.pq\")\n",
    "df_qesg = df_qesg.loc[df_qesg.y.notna()]\n",
    "df_qesg = df_qesg.loc[df_qesg.y != '기타']\n",
    "df_qesg = df_qesg.loc[df_qesg.y != '제외']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "826e2161-3563-4570-a0a9-a9f296a2d508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.unique(df_qesg.y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12df1ada-af2c-487d-9af3-a192b07cab76",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 데이터 클리닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6c08d8-3cfc-4ea1-9cc3-10ce6c58e001",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 짧은 본문 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc380ebf-ddec-4fac-859d-4e0bee2dcf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_contents_clean(row):\n",
    "    c = row.contents\n",
    "    cc = row.contents_clean\n",
    "    \n",
    "    if len(c) == 0:\n",
    "        return False\n",
    "    \n",
    "    if len(cc)/len(c)> 0.7:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69cf2fc7-cc2e-4832-8487-d92db97033fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bol_list = [ check_contents_clean(row) for i , row in df_qesg.iterrows() ]\n",
    "df_qesg['size'] = df_qesg[bol_list].contents_clean.apply(lambda x : len(x))\n",
    "df_qesg = df_qesg.loc[df_qesg['size'] > 40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c610c09-c74c-4b72-94b6-b2107e0763b1",
   "metadata": {},
   "source": [
    "# BERT 임베딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "082201fe-a739-435b-86ca-6c78e3c078ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, labels, max_seq_len, tokenizer):\n",
    "    \n",
    "    input_ids, attention_masks, token_type_ids, data_labels = [], [], [], []\n",
    "    \n",
    "    for example, label in tqdm(zip(examples, labels), total=len(examples)):\n",
    "        input_id = tokenizer.encode(example, max_length=max_seq_len, pad_to_max_length=True)\n",
    "        padding_count = input_id.count(tokenizer.pad_token_id)\n",
    "        attention_mask = [1] * (max_seq_len - padding_count) + [0] * padding_count\n",
    "        token_type_id = [0] * max_seq_len\n",
    "\n",
    "        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n",
    "        assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(len(attention_mask), max_seq_len)\n",
    "        assert len(token_type_id) == max_seq_len, \"Error with token type length {} vs {}\".format(len(token_type_id), max_seq_len)\n",
    "\n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        data_labels.append(label)\n",
    "\n",
    "    input_ids = np.array(input_ids, dtype=int)\n",
    "    attention_masks = np.array(attention_masks, dtype=int)\n",
    "    token_type_ids = np.array(token_type_ids, dtype=int)\n",
    "\n",
    "    data_labels = np.asarray(data_labels, dtype=np.int32)\n",
    "\n",
    "    return (input_ids, attention_masks, token_type_ids), data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d7f30fb-ae9f-48e4-9b78-f6a842598f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer \n",
    "max_seq_len = 2028\n",
    "tokenizer = BertTokenizer.from_pretrained('klue/bert-base', truncation=True, max_seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e518bd76-f57e-41ea-a8ce-fee4096e2c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 라벨 숫자 인코딩\n",
    "lbl_name = sorted(df_qesg['y'].unique().tolist())\n",
    "lbl_num = list(range(len(lbl_name)))\n",
    "lbl_name2num = dict(zip(lbl_name,lbl_num))\n",
    "lbl_num2name = dict(zip(lbl_num,lbl_name))\n",
    "df_qesg['y2num']  = df_qesg.y.apply(lambda x : lbl_name2num[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97ac2f3-71c8-429f-a203-170fc6a3955e",
   "metadata": {},
   "source": [
    "# 트레이닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c7b2bbe-537f-4600-b5bb-1d40f45dc57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_qesg['contents_clean'].tolist())\n",
    "y = np.array(df_qesg['y2num'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0337452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원큐\n",
    "class_weights = class_weight.compute_class_weight(class_weight  = 'balanced',classes= np.unique(y), y = y) \n",
    "class_weights_dict = dict(zip(  list(range(len(class_weights))),class_weights))\n",
    "\n",
    "X_train = tokenizer(X.tolist(), truncation=True, padding=True)\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(X_train),\n",
    "    y\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de7894f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del tokenizer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6bdcfc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  indices[1] = 22 is not in [0, 14)\n\t [[{{node GatherV2}}]]\n\t [[IteratorGetNext]]\n\t [[gradient_tape/tf_bert_for_sequence_classification_221/bert/embeddings/Gather_2/Size/_16]]\n  (1) INVALID_ARGUMENT:  indices[1] = 22 is not in [0, 14)\n\t [[{{node GatherV2}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_14692391]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38290/3589446714.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m history =model.fit(\n\u001b[0m\u001b[1;32m      8\u001b[0m train_dataset.shuffle(1000).batch(16), epochs=10, batch_size=16,class_weight= class_weights_dict,)\n",
      "\u001b[0;32m~/anaconda3/envs/esgmedia/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/esgmedia/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  indices[1] = 22 is not in [0, 14)\n\t [[{{node GatherV2}}]]\n\t [[IteratorGetNext]]\n\t [[gradient_tape/tf_bert_for_sequence_classification_221/bert/embeddings/Gather_2/Size/_16]]\n  (1) INVALID_ARGUMENT:  indices[1] = 22 is not in [0, 14)\n\t [[{{node GatherV2}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_14692391]"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=df_qesg['y2num'].nunique(), from_pt=True)\n",
    "loss =tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "history =model.fit(\n",
    "train_dataset.shuffle(1000).batch(16), epochs=10, batch_size=16,class_weight= class_weights_dict,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049ebd05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f89ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_qesg['contents_clean'].tolist())\n",
    "y = np.array(df_qesg['y2num'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20bc9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = len(X)//400 \n",
    "max_seq_len = 2028\n",
    "for i in tqdm(range(401)):\n",
    "    if i < 210:\n",
    "        continue\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained('klue/bert-base', truncation=True, max_seq_len=max_seq_len)\n",
    "\n",
    "    idx_start = chunk_size * i\n",
    "    idx_end = chunk_size * (i+1)\n",
    "    x_src = X.tolist()[idx_start:idx_end]\n",
    "    X_train = tokenizer(x_src, truncation=True, padding=True)\n",
    "    del tokenizer\n",
    "\n",
    "    model = TFBertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=df_qesg['y2num'].nunique(), from_pt=True)\n",
    "    model.load_weights('model_weight_28_embedding')\n",
    "    xtr = X_train \n",
    "    res_emb = model.bert.embeddings(xtr['input_ids'],xtr['attention_mask'],xtr['token_type_ids'])\n",
    "    del model\n",
    "    pickle.dump(res_emb,open(f'./embd/{i:03d}.plk','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88aac7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1ddf84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ab5de5070ba7f03c4085b6b32b1632173f3a8358d404b2f0a0d9aec38557c606"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
